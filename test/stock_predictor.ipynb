{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a watered-down version of project 4 from the [fintech bootcamp at home](https://github.com/whitgroves/fintech-bootcamp-at-home) used with some models from my [optiver Kaggle submission](https://github.com/whitgroves/optiver-trading-at-the-close) to test the ensemble's performance. Feel free to treat this as a setup guide if you need an example and/or use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/Data/Repos/clique-ml/.cuda/bin:/usr/local/cuda/bin:/home/whitgroves/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/snap/bin\n"
     ]
    }
   ],
   "source": [
    "!echo $PATH # if /usr/local/cuda/bin is missing, re-run VScode form terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ptxas: NVIDIA (R) Ptx optimizing assembler\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Tue_Jun_13_19:13:58_PDT_2023\n",
      "Cuda compilation tools, release 12.2, V12.2.91\n",
      "Build cuda_12.2.r12.2/compiler.32965470_0\n"
     ]
    }
   ],
   "source": [
    "!ptxas --version # expecting 12.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>trade_count</th>\n",
       "      <th>vwap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>NKLA</td>\n",
       "      <td>2022-01-03 05:00:00+00:00</td>\n",
       "      <td>10.0200</td>\n",
       "      <td>10.3191</td>\n",
       "      <td>9.7500</td>\n",
       "      <td>10.2400</td>\n",
       "      <td>12750229.0</td>\n",
       "      <td>61421.0</td>\n",
       "      <td>10.077616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>NKLA</td>\n",
       "      <td>2022-01-04 05:00:00+00:00</td>\n",
       "      <td>10.2200</td>\n",
       "      <td>10.3900</td>\n",
       "      <td>9.8350</td>\n",
       "      <td>10.3200</td>\n",
       "      <td>11373741.0</td>\n",
       "      <td>54861.0</td>\n",
       "      <td>10.120397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>NKLA</td>\n",
       "      <td>2022-01-05 05:00:00+00:00</td>\n",
       "      <td>10.6800</td>\n",
       "      <td>11.5100</td>\n",
       "      <td>9.8500</td>\n",
       "      <td>9.8800</td>\n",
       "      <td>36341451.0</td>\n",
       "      <td>159097.0</td>\n",
       "      <td>10.662359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>NKLA</td>\n",
       "      <td>2022-01-06 05:00:00+00:00</td>\n",
       "      <td>10.2340</td>\n",
       "      <td>10.8000</td>\n",
       "      <td>9.6450</td>\n",
       "      <td>10.2100</td>\n",
       "      <td>26383343.0</td>\n",
       "      <td>112858.0</td>\n",
       "      <td>10.185134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>NKLA</td>\n",
       "      <td>2022-01-07 05:00:00+00:00</td>\n",
       "      <td>10.2100</td>\n",
       "      <td>10.7550</td>\n",
       "      <td>10.1100</td>\n",
       "      <td>10.6200</td>\n",
       "      <td>14584682.0</td>\n",
       "      <td>65934.0</td>\n",
       "      <td>10.487543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>NKLA</td>\n",
       "      <td>2024-01-17 05:00:00+00:00</td>\n",
       "      <td>0.6298</td>\n",
       "      <td>0.6357</td>\n",
       "      <td>0.6034</td>\n",
       "      <td>0.6332</td>\n",
       "      <td>56436368.0</td>\n",
       "      <td>71343.0</td>\n",
       "      <td>0.622183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>NKLA</td>\n",
       "      <td>2024-01-18 05:00:00+00:00</td>\n",
       "      <td>0.6551</td>\n",
       "      <td>0.6700</td>\n",
       "      <td>0.5825</td>\n",
       "      <td>0.6218</td>\n",
       "      <td>101971452.0</td>\n",
       "      <td>107485.0</td>\n",
       "      <td>0.620318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>NKLA</td>\n",
       "      <td>2024-01-19 05:00:00+00:00</td>\n",
       "      <td>0.6218</td>\n",
       "      <td>0.6700</td>\n",
       "      <td>0.6028</td>\n",
       "      <td>0.6521</td>\n",
       "      <td>82251930.0</td>\n",
       "      <td>85288.0</td>\n",
       "      <td>0.640258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>NKLA</td>\n",
       "      <td>2024-01-22 05:00:00+00:00</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>0.6880</td>\n",
       "      <td>0.6301</td>\n",
       "      <td>0.6517</td>\n",
       "      <td>75830657.0</td>\n",
       "      <td>78571.0</td>\n",
       "      <td>0.659761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>NKLA</td>\n",
       "      <td>2024-01-23 05:00:00+00:00</td>\n",
       "      <td>0.6713</td>\n",
       "      <td>0.6920</td>\n",
       "      <td>0.6321</td>\n",
       "      <td>0.6373</td>\n",
       "      <td>42606528.0</td>\n",
       "      <td>46311.0</td>\n",
       "      <td>0.659642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>516 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     symbol                  timestamp     open     high      low    close  \\\n",
       "516    NKLA  2022-01-03 05:00:00+00:00  10.0200  10.3191   9.7500  10.2400   \n",
       "517    NKLA  2022-01-04 05:00:00+00:00  10.2200  10.3900   9.8350  10.3200   \n",
       "518    NKLA  2022-01-05 05:00:00+00:00  10.6800  11.5100   9.8500   9.8800   \n",
       "519    NKLA  2022-01-06 05:00:00+00:00  10.2340  10.8000   9.6450  10.2100   \n",
       "520    NKLA  2022-01-07 05:00:00+00:00  10.2100  10.7550  10.1100  10.6200   \n",
       "...     ...                        ...      ...      ...      ...      ...   \n",
       "1027   NKLA  2024-01-17 05:00:00+00:00   0.6298   0.6357   0.6034   0.6332   \n",
       "1028   NKLA  2024-01-18 05:00:00+00:00   0.6551   0.6700   0.5825   0.6218   \n",
       "1029   NKLA  2024-01-19 05:00:00+00:00   0.6218   0.6700   0.6028   0.6521   \n",
       "1030   NKLA  2024-01-22 05:00:00+00:00   0.6400   0.6880   0.6301   0.6517   \n",
       "1031   NKLA  2024-01-23 05:00:00+00:00   0.6713   0.6920   0.6321   0.6373   \n",
       "\n",
       "           volume  trade_count       vwap  \n",
       "516    12750229.0      61421.0  10.077616  \n",
       "517    11373741.0      54861.0  10.120397  \n",
       "518    36341451.0     159097.0  10.662359  \n",
       "519    26383343.0     112858.0  10.185134  \n",
       "520    14584682.0      65934.0  10.487543  \n",
       "...           ...          ...        ...  \n",
       "1027   56436368.0      71343.0   0.622183  \n",
       "1028  101971452.0     107485.0   0.620318  \n",
       "1029   82251930.0      85288.0   0.640258  \n",
       "1030   75830657.0      78571.0   0.659761  \n",
       "1031   42606528.0      46311.0   0.659642  \n",
       "\n",
       "[516 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random as r\n",
    "\n",
    "df = pd.read_csv('./stock_bars.csv')\n",
    "df = df.loc[df.symbol == r.choice(df.symbol.unique())] # pick a single stock from the test data each time\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>trade_count</th>\n",
       "      <th>vwap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>NKLA</td>\n",
       "      <td>2022-01-03 05:00:00+00:00</td>\n",
       "      <td>2.255504</td>\n",
       "      <td>2.227298</td>\n",
       "      <td>2.308932</td>\n",
       "      <td>2.354789</td>\n",
       "      <td>-0.499379</td>\n",
       "      <td>-0.131881</td>\n",
       "      <td>2.288845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>NKLA</td>\n",
       "      <td>2022-01-04 05:00:00+00:00</td>\n",
       "      <td>2.326172</td>\n",
       "      <td>2.251452</td>\n",
       "      <td>2.340183</td>\n",
       "      <td>2.383214</td>\n",
       "      <td>-0.526871</td>\n",
       "      <td>-0.240642</td>\n",
       "      <td>2.304003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>NKLA</td>\n",
       "      <td>2022-01-05 05:00:00+00:00</td>\n",
       "      <td>2.488709</td>\n",
       "      <td>2.633016</td>\n",
       "      <td>2.345697</td>\n",
       "      <td>2.226875</td>\n",
       "      <td>-0.028207</td>\n",
       "      <td>1.487530</td>\n",
       "      <td>2.496032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>NKLA</td>\n",
       "      <td>2022-01-06 05:00:00+00:00</td>\n",
       "      <td>2.331119</td>\n",
       "      <td>2.391132</td>\n",
       "      <td>2.270329</td>\n",
       "      <td>2.344129</td>\n",
       "      <td>-0.227094</td>\n",
       "      <td>0.720914</td>\n",
       "      <td>2.326941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>NKLA</td>\n",
       "      <td>2022-01-07 05:00:00+00:00</td>\n",
       "      <td>2.322639</td>\n",
       "      <td>2.375801</td>\n",
       "      <td>2.441286</td>\n",
       "      <td>2.489809</td>\n",
       "      <td>-0.462741</td>\n",
       "      <td>-0.057058</td>\n",
       "      <td>2.434091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>NKLA</td>\n",
       "      <td>2024-01-17 05:00:00+00:00</td>\n",
       "      <td>-1.062431</td>\n",
       "      <td>-1.071668</td>\n",
       "      <td>-1.053818</td>\n",
       "      <td>-1.058651</td>\n",
       "      <td>0.373136</td>\n",
       "      <td>0.032620</td>\n",
       "      <td>-1.061422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>NKLA</td>\n",
       "      <td>2024-01-18 05:00:00+00:00</td>\n",
       "      <td>-1.053492</td>\n",
       "      <td>-1.059983</td>\n",
       "      <td>-1.061502</td>\n",
       "      <td>-1.062702</td>\n",
       "      <td>1.282578</td>\n",
       "      <td>0.631833</td>\n",
       "      <td>-1.062083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>NKLA</td>\n",
       "      <td>2024-01-19 05:00:00+00:00</td>\n",
       "      <td>-1.065258</td>\n",
       "      <td>-1.059983</td>\n",
       "      <td>-1.054039</td>\n",
       "      <td>-1.051936</td>\n",
       "      <td>0.888733</td>\n",
       "      <td>0.263820</td>\n",
       "      <td>-1.055017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>NKLA</td>\n",
       "      <td>2024-01-22 05:00:00+00:00</td>\n",
       "      <td>-1.058827</td>\n",
       "      <td>-1.053851</td>\n",
       "      <td>-1.044002</td>\n",
       "      <td>-1.052078</td>\n",
       "      <td>0.760485</td>\n",
       "      <td>0.152456</td>\n",
       "      <td>-1.048107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>NKLA</td>\n",
       "      <td>2024-01-23 05:00:00+00:00</td>\n",
       "      <td>-1.047768</td>\n",
       "      <td>-1.052488</td>\n",
       "      <td>-1.043267</td>\n",
       "      <td>-1.057195</td>\n",
       "      <td>0.096921</td>\n",
       "      <td>-0.382396</td>\n",
       "      <td>-1.048149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>516 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     symbol                  timestamp      open      high       low  \\\n",
       "516    NKLA  2022-01-03 05:00:00+00:00  2.255504  2.227298  2.308932   \n",
       "517    NKLA  2022-01-04 05:00:00+00:00  2.326172  2.251452  2.340183   \n",
       "518    NKLA  2022-01-05 05:00:00+00:00  2.488709  2.633016  2.345697   \n",
       "519    NKLA  2022-01-06 05:00:00+00:00  2.331119  2.391132  2.270329   \n",
       "520    NKLA  2022-01-07 05:00:00+00:00  2.322639  2.375801  2.441286   \n",
       "...     ...                        ...       ...       ...       ...   \n",
       "1027   NKLA  2024-01-17 05:00:00+00:00 -1.062431 -1.071668 -1.053818   \n",
       "1028   NKLA  2024-01-18 05:00:00+00:00 -1.053492 -1.059983 -1.061502   \n",
       "1029   NKLA  2024-01-19 05:00:00+00:00 -1.065258 -1.059983 -1.054039   \n",
       "1030   NKLA  2024-01-22 05:00:00+00:00 -1.058827 -1.053851 -1.044002   \n",
       "1031   NKLA  2024-01-23 05:00:00+00:00 -1.047768 -1.052488 -1.043267   \n",
       "\n",
       "         close    volume  trade_count      vwap  \n",
       "516   2.354789 -0.499379    -0.131881  2.288845  \n",
       "517   2.383214 -0.526871    -0.240642  2.304003  \n",
       "518   2.226875 -0.028207     1.487530  2.496032  \n",
       "519   2.344129 -0.227094     0.720914  2.326941  \n",
       "520   2.489809 -0.462741    -0.057058  2.434091  \n",
       "...        ...       ...          ...       ...  \n",
       "1027 -1.058651  0.373136     0.032620 -1.061422  \n",
       "1028 -1.062702  1.282578     0.631833 -1.062083  \n",
       "1029 -1.051936  0.888733     0.263820 -1.055017  \n",
       "1030 -1.052078  0.760485     0.152456 -1.048107  \n",
       "1031 -1.057195  0.096921    -0.382396 -1.048149  \n",
       "\n",
       "[516 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def standardize(data:pd.DataFrame, skip_cols:list[str]=[]) -> pd.DataFrame:\n",
    "    skip_cols = [col for col in skip_cols if col in data.columns]\n",
    "    skip = data[skip_cols]\n",
    "    temp = data.drop(skip_cols, axis=1)\n",
    "    temp = (temp - temp.mean()) / temp.std(ddof=0) # standardize\n",
    "    temp = temp.ffill().fillna(0) # impute\n",
    "    return pd.concat([skip, temp], axis=1, join='inner')\n",
    "\n",
    "df = standardize(df, ['symbol', 'timestamp'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['low'].shift(-1) - df['low'] # since data is standardized, we learn/predict the difference between t-1 and t\n",
    "X = df.drop(['symbol', 'timestamp'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>trade_count</th>\n",
       "      <th>vwap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>2.255504</td>\n",
       "      <td>2.227298</td>\n",
       "      <td>2.308932</td>\n",
       "      <td>2.354789</td>\n",
       "      <td>-0.499379</td>\n",
       "      <td>-0.131881</td>\n",
       "      <td>2.288845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>2.326172</td>\n",
       "      <td>2.251452</td>\n",
       "      <td>2.340183</td>\n",
       "      <td>2.383214</td>\n",
       "      <td>-0.526871</td>\n",
       "      <td>-0.240642</td>\n",
       "      <td>2.304003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>2.488709</td>\n",
       "      <td>2.633016</td>\n",
       "      <td>2.345697</td>\n",
       "      <td>2.226875</td>\n",
       "      <td>-0.028207</td>\n",
       "      <td>1.487530</td>\n",
       "      <td>2.496032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>2.331119</td>\n",
       "      <td>2.391132</td>\n",
       "      <td>2.270329</td>\n",
       "      <td>2.344129</td>\n",
       "      <td>-0.227094</td>\n",
       "      <td>0.720914</td>\n",
       "      <td>2.326941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>2.322639</td>\n",
       "      <td>2.375801</td>\n",
       "      <td>2.441286</td>\n",
       "      <td>2.489809</td>\n",
       "      <td>-0.462741</td>\n",
       "      <td>-0.057058</td>\n",
       "      <td>2.434091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>-1.062431</td>\n",
       "      <td>-1.071668</td>\n",
       "      <td>-1.053818</td>\n",
       "      <td>-1.058651</td>\n",
       "      <td>0.373136</td>\n",
       "      <td>0.032620</td>\n",
       "      <td>-1.061422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>-1.053492</td>\n",
       "      <td>-1.059983</td>\n",
       "      <td>-1.061502</td>\n",
       "      <td>-1.062702</td>\n",
       "      <td>1.282578</td>\n",
       "      <td>0.631833</td>\n",
       "      <td>-1.062083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>-1.065258</td>\n",
       "      <td>-1.059983</td>\n",
       "      <td>-1.054039</td>\n",
       "      <td>-1.051936</td>\n",
       "      <td>0.888733</td>\n",
       "      <td>0.263820</td>\n",
       "      <td>-1.055017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>-1.058827</td>\n",
       "      <td>-1.053851</td>\n",
       "      <td>-1.044002</td>\n",
       "      <td>-1.052078</td>\n",
       "      <td>0.760485</td>\n",
       "      <td>0.152456</td>\n",
       "      <td>-1.048107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>-1.047768</td>\n",
       "      <td>-1.052488</td>\n",
       "      <td>-1.043267</td>\n",
       "      <td>-1.057195</td>\n",
       "      <td>0.096921</td>\n",
       "      <td>-0.382396</td>\n",
       "      <td>-1.048149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>516 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          open      high       low     close    volume  trade_count      vwap\n",
       "516   2.255504  2.227298  2.308932  2.354789 -0.499379    -0.131881  2.288845\n",
       "517   2.326172  2.251452  2.340183  2.383214 -0.526871    -0.240642  2.304003\n",
       "518   2.488709  2.633016  2.345697  2.226875 -0.028207     1.487530  2.496032\n",
       "519   2.331119  2.391132  2.270329  2.344129 -0.227094     0.720914  2.326941\n",
       "520   2.322639  2.375801  2.441286  2.489809 -0.462741    -0.057058  2.434091\n",
       "...        ...       ...       ...       ...       ...          ...       ...\n",
       "1027 -1.062431 -1.071668 -1.053818 -1.058651  0.373136     0.032620 -1.061422\n",
       "1028 -1.053492 -1.059983 -1.061502 -1.062702  1.282578     0.631833 -1.062083\n",
       "1029 -1.065258 -1.059983 -1.054039 -1.051936  0.888733     0.263820 -1.055017\n",
       "1030 -1.058827 -1.053851 -1.044002 -1.052078  0.760485     0.152456 -1.048107\n",
       "1031 -1.047768 -1.052488 -1.043267 -1.057195  0.096921    -0.382396 -1.048149\n",
       "\n",
       "[516 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "516     0.031250\n",
       "517     0.005515\n",
       "518    -0.075368\n",
       "519     0.170957\n",
       "520    -0.125001\n",
       "          ...   \n",
       "1027   -0.007684\n",
       "1028    0.007463\n",
       "1029    0.010037\n",
       "1030    0.000735\n",
       "1031         NaN\n",
       "Name: low, Length: 516, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-21 20:31:10.976804: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-21 20:31:10.984195: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753147870.992644  106819 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753147870.995189  106819 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753147871.001798  106819 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753147871.001805  106819 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753147871.001806  106819 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753147871.001807  106819 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-21 20:31:11.004065: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "I0000 00:00:1753147872.158071  106819 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1100 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "I0000 00:00:1753147872.158521  106819 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 4657 MB memory:  -> device: 1, name: NVIDIA GeForce GTX 1660 SUPER, pci bus id: 0000:06:00.0, compute capability: 7.5\n",
      "/mnt/Data/Repos/clique-ml/.cuda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cat\n",
    "import tensorflow as tf\n",
    "layers = tf.keras.layers\n",
    "Sequential = tf.keras.Sequential\n",
    "\n",
    "N_FEATURES = len(X.columns)\n",
    "ACTIVATION_1 = 'tanh' # inputs are standardized (vs normalized) so keep negative range\n",
    "ACTIVATION_2 = 'relu' # performed better than tanh, sigmoid\n",
    "DROPOUT = 0.5         # performed better than 0.3, 0.4\n",
    "RANDOM_SEED = 25      # even funnier that 24\n",
    "\n",
    "tf.keras.utils.set_random_seed(RANDOM_SEED)\n",
    "shared_kw = dict(random_state=RANDOM_SEED, learning_rate=0.2, max_depth=3, subsample=0.8)\n",
    "xgb_lgb_kw = dict(n_jobs=16, colsample_bytree=0.85, reg_alpha=500)\n",
    "xgb_cat_kw = dict(early_stopping_rounds=5)\n",
    "lgb_cat_kw = dict(num_leaves=8, min_child_samples=2000)\n",
    "regularizer = tf.keras.regularizers.l1(0.001)\n",
    "\n",
    "models = [ # order matters if limit is set; frontloading stronger models will cause more rejections; the reverse will oversaturate\n",
    "    xgb.XGBRegressor(**shared_kw, **xgb_lgb_kw, **xgb_cat_kw, eval_metric='mae', tree_method='hist', gamma=0.2),\n",
    "    lgb.LGBMRegressor(**shared_kw, **xgb_lgb_kw, **lgb_cat_kw, early_stopping_round=5, metric='l1', min_split_gain=0.001, verbosity=-1),\n",
    "    cat.CatBoostRegressor(**shared_kw, **xgb_cat_kw, **lgb_cat_kw, eval_metric='MAE'),\n",
    "    Sequential([layers.Dense(1, activation=ACTIVATION_1, input_shape=[N_FEATURES])], name='linear'), # N -> 1\n",
    "    Sequential([ # N -> N/2 -> 1\n",
    "        layers.Dense(N_FEATURES, kernel_regularizer=regularizer, activation=ACTIVATION_1, input_shape=[N_FEATURES]),\n",
    "        layers.Dropout(DROPOUT),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(N_FEATURES//2, kernel_regularizer=regularizer, activation=ACTIVATION_2),\n",
    "        layers.Dropout(DROPOUT),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(1)\n",
    "    ], name='net'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Clique (5 model(s); limit: none)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import clique\n",
    "cutoff = int(len(X)*0.8) # 80/20 train/test split\n",
    "training_inputs, testing_inputs = X[:cutoff], X[cutoff:-1]\n",
    "training_targets, testing_targets = y[:cutoff], y[cutoff:-1]\n",
    "ensemble = clique.Clique(models=models, inputs=testing_inputs, targets=testing_targets)\n",
    "ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble.load('.models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ensemble on fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1753147872.758024  106969 service.cc:152] XLA service 0x79ce840058a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1753147872.758040  106969 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "I0000 00:00:1753147872.758043  106969 service.cc:160]   StreamExecutor device (1): NVIDIA GeForce GTX 1660 SUPER, Compute Capability 7.5\n",
      "2025-07-21 20:31:12.768437: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1753147872.796305  106969 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1753147872.917962  106969 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ensemble on fold 2\n",
      "Training ensemble on fold 3\n",
      "Training ensemble on fold 4\n",
      "Training ensemble on fold 5\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "for fold, (training, validation) in enumerate(TimeSeriesSplit().split(training_inputs)):\n",
    "    print(f'Training ensemble on fold {fold+1}')\n",
    "    val_data = [(training_inputs.iloc[validation, :], training_targets.iloc[validation])]\n",
    "    for model in ensemble:\n",
    "        fit_kw = dict()\n",
    "        predict_kw = dict()\n",
    "        match model.model_type:\n",
    "            case 'Sequential' | 'Model':\n",
    "                if fold == 0: model.compile(optimizer='adam', loss='mae')\n",
    "                keras_kw = dict(verbose=0, batch_size=256)\n",
    "                fit_kw.update(keras_kw)\n",
    "                predict_kw.update(keras_kw)\n",
    "            case 'LGBMRegressor':\n",
    "                fit_kw.update(dict(eval_set=val_data, eval_metric='l1'))\n",
    "            case 'XGBRegressor' | 'CatBoostRegressor':\n",
    "                fit_kw.update(dict(verbose=0, eval_set=val_data))\n",
    "        model.fit_kw = fit_kw\n",
    "        model.predict_kw = predict_kw\n",
    "    ensemble.fit(training_inputs.iloc[training, :], training_targets.iloc[training])\n",
    "    del val_data\n",
    "    while gc.collect() > 0: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26888381411715034"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = ensemble.predict(testing_inputs)\n",
    "performance = ensemble.scoring(testing_targets, predictions)\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Clique (5 model(s); limit: none)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28230200708743014"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble.mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01815294646628095"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelProfile (CatBoostRegressor)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble.best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Clique (5 model(s); limit: none)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble.save('.models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x79cf8811c9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 145ms/stepWARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x79cf8811c9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Clique (3 model(s); limit: 3)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclusive = clique.Clique(models='.models/', limit=3, inputs=testing_inputs, targets=testing_targets).evaluate().prune()\n",
    "exclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01815294646628095"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclusive.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelProfile (CatBoostRegressor)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclusive.best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "EvaluationError",
     "evalue": "Testing inputs and targets have not been defined.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEvaluationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m clique\u001b[38;5;241m.\u001b[39mClique(models\u001b[38;5;241m=\u001b[39mmodels)\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.untrained/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mclique\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mClique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.untrained/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# EvaluationError\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/Data/Repos/clique-ml/src/clique/clique.py:277\u001b[0m, in \u001b[0;36mClique.evaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mevaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m    272\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;124;03m    Scores all of the models in the ensemble against the ensemble's testing data and scoring function.\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;124;03m    Raises an error if the test data has not been set, or the scoring function is not configured properly.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m    Returns the instance for method chaining.\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mraise\u001b[39;00m EvaluationError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTesting inputs and targets have not been defined.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcan_evaluate: \u001b[38;5;28;01mraise\u001b[39;00m EvaluationError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot evaluate models before they are trained. Call `fit` first.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m: model\u001b[38;5;241m.\u001b[39mscore \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets, model\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs))\n",
      "\u001b[0;31mEvaluationError\u001b[0m: Testing inputs and targets have not been defined."
     ]
    }
   ],
   "source": [
    "clique.Clique(models=models).save('.untrained/')\n",
    "clique.Clique(models='.untrained/').evaluate() # EvaluationError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
